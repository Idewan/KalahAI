import sys

import numpy as np

from tqdm import tqdm 
from . import KalahNet as kn

sys.path.append('../')
from python_agent.side import Side

import torch
import torch.optim as optim
class AverageMeter(object):
    def __init__(self):
        self.val = 0
        self.avg = 0
        self.sum = 0
        self.count = 0
    
    def __repr__(self):
        return f'{self.avg:.2e}'
    
    def update(self, val, n=1):
        self.val = val
        self.sum += val * n 
        self.count += n
        self.avg = self.sum / self.count

class KalahNetTrain(object):

    def __init__(self, env, batch_size, device, epochs, lr=0.001, dropout=0.3, iteration=0.2):
        """
            Initialize the training class for KalahNet NN class

            :param env: Kalah_train environment
            :param batch_size: Training batchsize
            :param device: Cuda enabled or not
            :param epochs: Number of epochs to train 
            :param lr: learning rate
            :param dropout: Probability of drop out in dropout layers
        """

        #Initialize neural net
        self.device = device
        self.is_cuda = torch.cuda.is_available()
        self.nnet = kn.KalahNet(7, dropout).to(self.device).double()
        self.env = env
        self.iter = iteration

        #Training parameters
        self.batch_size = batch_size
        self.lr = lr 
        self.epochs = epochs
    
    def train(self, memory):
        """
            Train the neural network according to a combination of 
            sum of mean squared error and cross-entropy loss
            
            l = (z − v)^2 − πTlog p + c||θ||2

            :param memory: memory of examples generated by MCTS
            :return: returns nothing
        """
        optimizer = optim.Adam(self.nnet.parameters())
        # self.iter+=1
        # if self.iter % 500 == 0:
        #     self.lr /= 10
        # print(self.iter)
        for epoch in range(self.epochs):
            print(f'EPOCH: {epoch +1}')
            self.nnet.train()
            pi_losses = AverageMeter()
            v_losses = AverageMeter()

            batch_count = int(len(memory) / self.batch_size)

            t = tqdm(range(batch_count), desc="Training Net")

            for _ in t:
                transitions = memory.sample(self.batch_size)
                batch = memory.Transition(*zip(*transitions))
                #Sequence batch into states, pi, values
 
                s = torch.cat(batch.state)
                pi = torch.cat(batch.pi)
                v = torch.cat(batch.v)

                s = torch.reshape(s, (self.batch_size, 16))
                pi = torch.reshape(pi, (self.batch_size, 8))
                v = torch.reshape(v, (self.batch_size, 1))

                if self.is_cuda:
                    s, pi, v = s.contiguous().cuda(), pi.contiguous().cuda(), v.contiguous().cuda()

                #Compute current pi and values given current nn
                output_pi, output_v = self.nnet(s)
                l_pi = self.loss_pi(pi, output_pi)
                l_v = self.loss_v(v, output_v)
                loss =  l_pi + l_v

                #Record loss
                pi_losses.update(l_pi.item(), self.batch_size)
                v_losses.update(l_v.item(), self.batch_size)
                t.set_postfix(Loss_pi=pi_losses, Loss_v=v_losses)

                #Compute gradient and perform single step
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

    def predict(self, s):
        """
            Predicts what actions should be taken

            :param s: current state (kalah board) - view corrected
        """
        #Preparing input
        s = s.contiguous().cuda() if self.is_cuda else s
        self.nnet.eval()
        with torch.no_grad():
            pi, v = self.nnet(s.double().unsqueeze(0))
        
        return torch.exp(pi).data.cpu().numpy()[0], v.data.cpu().numpy()[0]

    
    def board_view_player(self, board=None, turn=None):
        """
            The board, [[side.South], [side.North]], is always south facing.
            This methods returns the board so that is facing that the current
            player's turn exists in the first row first column.

            :param board: Kalah board
            :return: returns Board facing correctly for the current player's turn
        """
        s = self.env.board.board.copy() if board is None else board.board.copy()
        p = self.env.turn if turn is None else turn

        if p == Side.NORTH:
            s[[0,1]] = s[[1,0]]
        
        s = s.astype(np.float64)
        s = torch.from_numpy(s.flatten())

        return s

    def loss_pi(self, targets, outputs):
        """
            :param targets: Target prob distribution
            :param outputs: Output prob distribution
        """
        return -torch.sum(targets * outputs) / targets.size()[0]

    def loss_v(self, targets, outputs):
        """
            :param targets: Target values
            :param outputs: Output values
        """
        # print(targets.shape)
        # print(outputs.s)
        return torch.sum((targets - outputs.view(-1)) ** 2) / targets.size()[0]

    def save_model_checkpoint(self, path):
        """
            :param filename: name of the file/dir
            :param title: title of the weights file
        """
        torch.save(self.nnet.state_dict(), path)

    def load_model_checkpoint(self, path):
        """
            :param filename: name of the file/dir
            :param title: title of the weights file
        """
        state_dict = torch.load(path, map_location= None if self.is_cuda else 'cpu')
        self.nnet.load_state_dict(state_dict)